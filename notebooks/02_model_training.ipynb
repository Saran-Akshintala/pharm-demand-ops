{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharmacy Demand Forecasting - Model Training\n",
    "\n",
    "This notebook builds and trains machine learning models for predicting pharmacy order quantities.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and preprocess the data\n",
    "2. Feature engineering and encoding\n",
    "3. Train baseline models (Linear Regression, Random Forest, XGBoost)\n",
    "4. Evaluate models using RMSE/MAE\n",
    "5. Save the best model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add app directory to path\n",
    "sys.path.append('../app')\n",
    "from utils import preprocess_sales_features, save_model, parse_order_scheme\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data from EDA\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed_data.csv')\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Creating sample data...\")\n",
    "    # Create sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    df = pd.DataFrame({\n",
    "        'L7': np.random.randint(0, 50, n_samples),\n",
    "        'L15': np.random.randint(0, 100, n_samples),\n",
    "        'L30': np.random.randint(0, 200, n_samples),\n",
    "        'L60': np.random.randint(0, 400, n_samples),\n",
    "        'Order': np.random.choice(['12', '9+1', '24', '6+1', '18', '15'], n_samples)\n",
    "    })\n",
    "    \n",
    "    # Parse orders\n",
    "    order_parsed = df['Order'].apply(parse_order_scheme)\n",
    "    df['Base_Quantity'] = [x[0] for x in order_parsed]\n",
    "    df['Scheme_Type'] = [x[1] for x in order_parsed]\n",
    "    \n",
    "    df = preprocess_sales_features(df)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_cols = [col for col in df.columns if col.startswith('L') or \n",
    "                col in ['sales_trend_7_15', 'sales_trend_15_30', 'avg_sales_velocity', \n",
    "                       'max_sales_period', 'sales_volatility']]\n",
    "\n",
    "target_col = 'Base_Quantity'\n",
    "\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "print(f\"Target column: {target_col}\")\n",
    "\n",
    "# Remove rows with missing target\n",
    "df_clean = df.dropna(subset=[target_col])\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "X = df_clean[feature_cols].fillna(0)\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled features for Linear Regression, original for tree-based\n",
    "    if name == 'Linear Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'RMSE': [results[model]['rmse'] for model in results.keys()],\n",
    "    'MAE': [results[model]['mae'] for model in results.keys()],\n",
    "    'R²': [results[model]['r2'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.loc[comparison_df['RMSE'].idxmin(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nBest model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Model comparison\n",
    "comparison_df.set_index('Model')[['RMSE', 'MAE']].plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Model Performance Comparison')\n",
    "axes[0, 0].set_ylabel('Error')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R² comparison\n",
    "comparison_df.set_index('Model')['R²'].plot(kind='bar', ax=axes[0, 1], color='green')\n",
    "axes[0, 1].set_title('R² Score Comparison')\n",
    "axes[0, 1].set_ylabel('R² Score')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Actual vs Predicted for best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "axes[1, 0].scatter(y_test, best_predictions, alpha=0.6)\n",
    "axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual')\n",
    "axes[1, 0].set_ylabel('Predicted')\n",
    "axes[1, 0].set_title(f'Actual vs Predicted - {best_model_name}')\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - best_predictions\n",
    "axes[1, 1].scatter(best_predictions, residuals, alpha=0.6)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Predicted')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title(f'Residuals Plot - {best_model_name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "    plt.title(f'Top 10 Feature Importance - {best_model_name}')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif best_model_name == 'Linear Regression':\n",
    "    # Coefficients for linear regression\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'coefficient': best_model.coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"Linear Regression Coefficients:\")\n",
    "    print(coefficients)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=coefficients.head(10), x='coefficient', y='feature')\n",
    "    plt.title('Top 10 Feature Coefficients - Linear Regression')\n",
    "    plt.xlabel('Coefficient')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_path = models_dir / 'order_predictor.pkl'\n",
    "save_model(best_model, str(model_path))\n",
    "print(f\"Best model saved to: {model_path}\")\n",
    "\n",
    "# Save scaler if needed\n",
    "if best_model_name == 'Linear Regression':\n",
    "    scaler_path = models_dir / 'scaler.pkl'\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save feature columns\n",
    "feature_info = {\n",
    "    'feature_columns': feature_cols,\n",
    "    'model_type': best_model_name,\n",
    "    'performance': {\n",
    "        'rmse': results[best_model_name]['rmse'],\n",
    "        'mae': results[best_model_name]['mae'],\n",
    "        'r2': results[best_model_name]['r2']\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(models_dir / 'model_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "\n",
    "print(\"Model training completed successfully!\")\n",
    "print(f\"Final model performance:\")\n",
    "print(f\"- RMSE: {results[best_model_name]['rmse']:.3f}\")\n",
    "print(f\"- MAE: {results[best_model_name]['mae']:.3f}\")\n",
    "print(f\"- R²: {results[best_model_name]['r2']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
